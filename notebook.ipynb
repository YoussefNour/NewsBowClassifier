{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import os\n\nASSETS_DIR = os.path.join(os.path.dirname(os.path.abspath(__name__)), 'assets')\nINPUTS_DIR = os.path.join(ASSETS_DIR, 'inputs')\nOUTPUTS_DIR = os.path.join(ASSETS_DIR, 'outputs')\nPICKLES_DIR = os.path.join(ASSETS_DIR, 'pickles')\n"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import re\ndef text_normalize(text):\n    text = str(text)\n    # denoise\n    noise = re.compile(\"\"\" ّ    | # Tashdid\n                             َ    | # Fatha\n                             ً    | # Tanwin Fath\n                             ُ    | # Damma\n                             ٌ    | # Tanwin Damm\n                             ِ    | # Kasra\n                             ٍ    | # Tanwin Kasr\n                             ْ    | # Sukun\n                             ـ   | # Tatwil/Kashida\n                             \"  # quotations \n                         \"\"\", re.VERBOSE)\n    text = re.sub(noise, '', text)\n    # text normalizer\n    text = re.sub(r\"أ|إ|آ\", \"ا\", text)\n    text = re.sub(r\"ء|ئ|ؤ\", \"ء\", text)\n    text = re.sub(r\"ى|ي\", \"ي\", text)\n    text = re.sub(r\"ه|ة\", \"ه\", text)\n\n    # number noramlize\n    text = re.sub(r\"\\d+\", \"NUM\", text)\n\n    # remove non letters\n    text = re.sub(r\"\\W\", \" \", text)\n    \n    # if the word is very small neglect it\n    text = \" \".join([word for word in text.split() if len(word) >= 3 ])\n\n    return text"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Sports       1\nEducation    1\nArt          1\nMedicine     1\nName: label, dtype: int64\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>نصر محروس انتظروا اغاني جديده مصطفي شوقي وسومه...</td>\n      <td>Art</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>تعلم الطالب رياض الاطفال وحتي الصف الثالث الاب...</td>\n      <td>Education</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>اطمن علي نفسك فحص البروستاتا ومتي يجب اجراءه n...</td>\n      <td>Medicine</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>NUM مباراه جمعت الزمالك والمقاولون اللقاء الاو...</td>\n      <td>Sports</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                text      label\n0  نصر محروس انتظروا اغاني جديده مصطفي شوقي وسومه...        Art\n1  تعلم الطالب رياض الاطفال وحتي الصف الثالث الاب...  Education\n2  اطمن علي نفسك فحص البروستاتا ومتي يجب اجراءه n...   Medicine\n3  NUM مباراه جمعت الزمالك والمقاولون اللقاء الاو...     Sports"},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"import pandas as pd\ndataset = pd.DataFrame(columns=['text', 'label'])\nfor file in os.listdir(INPUTS_DIR):\n    if not file.startswith('.'):\n        temp_df = pd.read_csv(os.path.join(INPUTS_DIR, file))\n        # apply normalizing\n        temp_df['text'] = temp_df['text'].apply(text_normalize)\n        text = \" \".join(temp_df['text'].values)\n        label = file.split(\".\")[0]\n        dataset = dataset.append({\n            \"text\": text,\n            \"label\": label\n        }, ignore_index = True) \nprint(dataset['label'].value_counts())\ndataset.head()"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":"TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.float64'>, encoding='utf-8',\n                input='content', lowercase=True, max_df=1.0, max_features=None,\n                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n                smooth_idf=True, stop_words=None, strip_accents=None,\n                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, use_idf=True, vocabulary=None)"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"vectorizer.fit(dataset['text'])"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"tf_idfs = pd.DataFrame(vectorizer.transform(dataset['text']).toarray(), columns=vectorizer.get_feature_names())\ntf_idfs.to_csv(\"tf-idfs.csv\")"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":"academy             NaN\nacademy بمغامرات    NaN\nact                 NaN\nact international   NaN\nact org             NaN\n                     ..\nﺷﺒهه اميتاب         NaN\nﺷﻜﺮي                NaN\nﺷﻜﺮي ﺳﺮﺣﺎن          NaN\nﻋﻤﺮي                NaN\nﻋﻤﺮي ھﺒﻘﻰ           NaN\nName: 0, Length: 123621, dtype: float64"},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"tf_idfs[tf_idfs>0.01].iloc[0, :]"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"tf_idfs = {}\nfor label in dataset['label'].unique():\n    tf_idfs[label] = vectorizer.transform(dataset.loc[dataset['label'] == label]['text'])"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"from sklearn.metrics.pairwise import linear_kernel\nimport operator\n\ndef classify(text):\n    text = text_normalize(text)\n    text_v = vectorizer.transform([text])\n    distances = {}\n    for key in tf_idfs.keys():\n        distances[key] = linear_kernel(text_v, tf_idfs[key]).flatten()[0]\n    return distances"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"for text input:\n ما توقعاتك لنتيجة لقاء #الأهلي و #غزل_المحلة في الدوري المصري اليوم؟ تنطلق في السابعة والنصف مساء\nSports\n\nfor text input:\n لأهلي يستقر على تشكيل مواجهة غزل المحلة فى الدوري\nSports\n\nfor text input:\n أسرع انتشارًا.. رصد سلالة جديدة من كورونا فى بريطانيا\nMedicine\n\nfor text input:\n برازيلية تحول منزلها لمستشفى دمى لإسعاد الأطفال فى زمن الكورونا\nMedicine\n\nfor text input:\n شوبير يعلن سلبية مسحة ثنائى منتخب الشباب وانفراجة لخوض مواجهة تونس\nSports\n\nfor text input:\n لوسى تودع 2020 بوصلة رقص على أغنية تامر عاشور باى باى.. فيديو وصور\nArt\n\nfor text input:\n إلهام شاهين تشكر ليوم السابع بعد ندوة الاحتفاء بتكريمها فى مهرجان القاهرة\nArt\n\nfor text input:\n شاهد رقصة مع آسر ياسين وموقف طريف فى عيد ميلاد نيللى كريم\nArt\n\nfor text input:\n حزب الغد لوزير التعليم نطالب بامتحان واحد شامل هذا العام والغاء امتحان نصف الترم\nEducation\n\nfor text input:\n عاجل : وزير التعليم : اليوم أكبر نسبة حضور في العام الدراسي ولابد من استكمال الدراسة\nEducation\n\nfor text input:\n أول نسخة ضوئية من قرارات وزير التعليم برفع الغياب ونظام التقويم\nEducation\n\n"}],"source":"texts = [\n    \"ما توقعاتك لنتيجة لقاء #الأهلي و #غزل_المحلة في الدوري المصري اليوم؟ تنطلق في السابعة والنصف مساء\",\n    \"لأهلي يستقر على تشكيل مواجهة غزل المحلة فى الدوري\",\n    \"أسرع انتشارًا.. رصد سلالة جديدة من كورونا فى بريطانيا\",\n    \"برازيلية تحول منزلها لمستشفى دمى لإسعاد الأطفال فى زمن الكورونا\",\n    \"شوبير يعلن سلبية مسحة ثنائى منتخب الشباب وانفراجة لخوض مواجهة تونس\",\n    \"لوسى تودع 2020 بوصلة رقص على أغنية تامر عاشور باى باى.. فيديو وصور\",\n    \"إلهام شاهين تشكر ليوم السابع بعد ندوة الاحتفاء بتكريمها فى مهرجان القاهرة\",\n    \"شاهد رقصة مع آسر ياسين وموقف طريف فى عيد ميلاد نيللى كريم\",\n    \"حزب الغد لوزير التعليم نطالب بامتحان واحد شامل هذا العام والغاء امتحان نصف الترم\",\n    \"عاجل : وزير التعليم : اليوم أكبر نسبة حضور في العام الدراسي ولابد من استكمال الدراسة\",\n    \"أول نسخة ضوئية من قرارات وزير التعليم برفع الغياب ونظام التقويم\"\n]\nfor text in texts:\n    distances = classify(text)\n    #print(\"for text input : {} ditances are :\".format(text))\n    #print(sorted(distances.items(), key=operator.itemgetter(1), reverse=True))\n    #print()\n    print(\"for text input:\\n {}\".format(text))\n    print(sorted(distances.items(), key=operator.itemgetter(1), reverse=True)[0][0])\n    print()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}